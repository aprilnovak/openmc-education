{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19a3dc7-f423-4e8c-9673-b79a2de4ca37",
   "metadata": {},
   "source": [
    "# Best Practices with OpenMC\n",
    "\n",
    "In this tutorial, we'll learn about how to use OpenMC efficiently and correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588df5b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lattices vs. Flat Geometries\n",
    "\n",
    "To obtain good tracking performance (particles/s that OpenMC can simulate), you should think carefully about how the geometry is constructed. In general, universes and lattices will perform better than \"flat\" universes, because when a particle moves into an adjacent cell, a lattice immediately has a \"rule\" for finding the identity of the adjacent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmc\n",
    "\n",
    "model = openmc.Model()\n",
    "model.settings.particles = 10000\n",
    "model.settings.inactive = 50\n",
    "model.settings.batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ac707",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = openmc.Material()\n",
    "mat1.add_element('U', 1.0)\n",
    "mat1.set_density('g/cm3', 11.0)\n",
    "\n",
    "mat2 = openmc.Material()\n",
    "mat2.add_nuclide('Pu239', 1.0)\n",
    "mat2.set_density('g/cm3', 11.0)\n",
    "\n",
    "zcyl = openmc.ZCylinder(r=0.4)\n",
    "cyl = openmc.Cell(fill=mat1, region=-zcyl)\n",
    "ocyl = openmc.Cell(fill=mat2, region=+zcyl)\n",
    "\n",
    "univ = openmc.Universe(cells=[ocyl, cyl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16930a4",
   "metadata": {},
   "source": [
    "Let's build a geometry containing $N^2$ squares all filled with this material, in one of two different ways:\n",
    "\n",
    "- a NxN rectilinear lattice (a \"nested\" geometry)\n",
    "- building the x-y planes and filling our universe into each slot (a \"flat\" geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16029f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "pitch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0d2a4",
   "metadata": {},
   "source": [
    "#### Option 1: Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9999951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_universe1.plot(width=(N*pitch,N*pitch), color_by='material', pixels=(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4424e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.geometry = openmc.Geometry(root_universe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statepoint = model.run(apply_tally_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff3365",
   "metadata": {},
   "source": [
    "### Option 2: \"Flat\" Geometry\n",
    "\n",
    "Let's build the same geometry, but now without using a lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e73c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []\n",
    "for x in range(len(xplanes) - 1):\n",
    "    for y in range(len(yplanes) - 1):\n",
    "        left = xplanes[x]\n",
    "        right = xplanes[x + 1]\n",
    "        bottom = yplanes[y]\n",
    "        top = yplanes[y + 1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_universe2 = openmc.Universe(cells=cells)\n",
    "root_universe2.plot(width=(N*pitch,N*pitch), pixels=(500,500))\n",
    "root_universe2.plot(width=(N*pitch,N*pitch), color_by='material', pixels=(500,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81c155",
   "metadata": {},
   "source": [
    "We have created an identical geometry! Of course, this took more human effort to establish instead of using a lattice. But that's not the only important difference -- this \"flat\" version of the geometry will also be *slower*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.geometry = openmc.Geometry(root_universe2)\n",
    "statepoint = model.run(apply_tally_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa511455",
   "metadata": {},
   "source": [
    "This model ran about 3x slower than a (physically identical) version using a lattice. If you can build your geometry to take advantage of lattices, it is a good idea to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0671be4b",
   "metadata": {},
   "source": [
    "# Using OpenMC Correctly\n",
    "\n",
    "Monte Carlo \"run strategy\" generally consists of three choices:\n",
    "\n",
    "- Number of batches (`model.settings.batches`)\n",
    "- Number of inactive batches (`model.settings.inactive`)\n",
    "- Number of particles per batch (`model.settings.particles`)\n",
    "- Number of generations per batch (`model.settings.generations_per_batch`)\n",
    "\n",
    "In addition, for k-eigenvalue calculations you elect the initial source distribution. We will individually explore each of these choices. First, let's describe what these terms mean exactly.\n",
    "\n",
    "### What is a generation?\n",
    "\n",
    "During each generation in OpenMC:\n",
    "\n",
    "- `model.settings.particles` sites are sampled from a bank of fission sites\n",
    "- Those particles are transported from birth until \"death\" (leakage or absorption)\n",
    "- Any new neutrons which are produced during their lifetime (e.g., from fission) have their birth position, energy, and angle stored in a new fission bank.\n",
    "\n",
    "Therefore, each time a new generation begins, the sites used to sample the neutron positions are those which were \"banked\" from the previous generation.\n",
    "\n",
    "### What is a batch?\n",
    "\n",
    "A batch is a group of generations as one statistical realization. By default, `model.settings.generations_per_batch` is unity, in which case a batch is synonymous with a generation.\n",
    "\n",
    "### What is an inactive batch?\n",
    "\n",
    "An inactive batch involves the transport of neutrons, but not accumulation of any tallies.\n",
    "\n",
    "### What is an active batch?\n",
    "\n",
    "An active batch involves the transport of neutrons AND accumulation of tallies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98ab62",
   "metadata": {},
   "source": [
    "## Inactive batches and initial source\n",
    "\n",
    "For the very first generation run in OpenMC (the first generation of the first batch), we don't yet have a bank of sites to sample neutrons from. Therefore, the user has to provide a \"guess\" for the starting source, using `model.settings.source`. By default, this source distribution is taken to be a point source at the origin. In all k-eigenvalue cases, you don't know the source distribution, so whatever choice you make is a GUESS. However, we don't want to start accumulating tally statistics until our guessed source distribution undergoes enough generations so that it has statistically converged. Otherwise, even if you run a high number of particles/batch, your answers will be WRONG (but PRECISE!).\n",
    "\n",
    "The factors you choose are:\n",
    "\n",
    "- The starting source distribution. Ideally, you'd like this to be as close as possible to the true source distribution.\n",
    "- The number of inactive batches. The higher this number is, the more likely you are to have evolved from your (WRONG) initial source to the true initial source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373af77",
   "metadata": {},
   "source": [
    "To explore these effects, let's choose an initial source distribution which is clearly not the correct, converged source distribution. When choosing a source distribution, we will use the [`openmc.stats` module](https://docs.openmc.org/en/stable/pythonapi/stats.html), which contains probability distributions to sample from which we can use for energy, angle, and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = openmc.examples.pwr_pin_cell()\n",
    "model.geometry.root_universe.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcd18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom = openmc.ZPlane(z0=-150, boundary_type='vacuum')\n",
    "top = openmc.ZPlane(z0=150, boundary_type='vacuum')\n",
    "\n",
    "box = openmc.model.RectangularPrism(0.63*2, 0.63*2, boundary_type='reflective')\n",
    "\n",
    "outer_cell = openmc.Cell(region=-box & +bottom & -top, fill=model.geometry.root_universe)\n",
    "root_universe = openmc.Universe(cells=[outer_cell])\n",
    "model.geometry.root_universe = root_universe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471c6b1",
   "metadata": {},
   "source": [
    "Let's make a source distribution which only exists over the lower half of the pincell -- as if the entire upper half had no fission at all. Clearly this is a very bad guess!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6be2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2273d97a",
   "metadata": {},
   "source": [
    "In order to \"see\" the effect of having a wrong initial source distribution, we will need to add a tally to visualize a quantity affected by a wrong source distribution. Let's take a look at the heating distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c989af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3de31d",
   "metadata": {},
   "source": [
    "Now, we will run this model with different choices for numbers of inactive batches. As long as we run enough inactive batches, we can evolve away from this very wrong source distribution to the true, cosine distribution we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495aef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.settings.particles = 1000 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in [10, 20, 100, 500]:\n",
    "    # run OpenMC multiple times\n",
    "        \n",
    "    ax.plot(heat.get_values().flatten(), label='{} inactive'.format(i))\n",
    "    \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Kappa-Fission (unnormalized)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50411b5",
   "metadata": {},
   "source": [
    "We can see that we need more and more inactive batches if we want our fission source distribution to approach the true distribution. If you increase the number of particles, the statistical noisiness will decrease, but it won't help us to get closer to the true distribution for the sampled source. As a rule of thumb on selecting the inactive batches:\n",
    "\n",
    "- Small problems (critical assemblies, pin cell): O(10) batches\n",
    "- Medium problems (assemblies, fast reactor): O(10)–O(100) batches\n",
    "- Large problems (PWR core, spent fuel pool): O(100)–O(1000) batches?\n",
    "\n",
    "The dominance ratio, or the ratio of the second-largest eigenvalue to the largest eigenvalue, dictates the convergence rate of power iteration (each generation in a Monte Carlo simulation is a power iteration).\n",
    "\n",
    "If we change our initial guess for the source distribution to something more realistic, we'll be able to use fewer inactive batches before we start collecting tally statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.settings.particles = 1000\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in [10, 20, 100, 500]:\n",
    "    # run OpenMC multiple times\n",
    "        \n",
    "    ax.plot(heat.get_values().flatten(), label='{} inactive'.format(i))\n",
    "    \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Kappa-Fission (unnormalized)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccac02e",
   "metadata": {},
   "source": [
    "## Shannon Entropy\n",
    "\n",
    "Shannon entropy is a concept from information theory that characterizes how much \"information\" a bit stream stores. In the context of eigenvalue calculations, it has been shown that when a source distibution is discretized over a mesh, the entropy of the source probability converges as the distribution itself reaches stationarity. Shannon entropy is defined as:\n",
    "\n",
    "$$ H = - \\sum_i p_i \\log_2 p_i $$\n",
    "\n",
    "where $p_i$ is the fraction of source particles in mesh cell $i$. In essence, we superimpose a mesh onto our geometry, and assess stationarity of the fission source by looking for stationarity in the Shannon entropy.\n",
    "\n",
    "We'll need to create a `RegularMesh` object that will be used to count source particles over and calculate Shannon entropy. We can use the same mesh used for talling the fission source earlier (though this is not a requirement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868047b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plt.plot(entropy)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Shannon entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc1f5b",
   "metadata": {},
   "source": [
    "You should choose your number of inactive batches once the Shannon entropy plateaus to a constant value. From this example, we are not using enough particles to see this trend, because our statistical noise is quite high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.settings.particles = 10000\n",
    "statepoint = model.run(output=False)\n",
    "\n",
    "with openmc.StatePoint(statepoint) as sp:\n",
    "    entropy = sp.entropy\n",
    "    \n",
    "plt.plot(entropy)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Shannon entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb6337",
   "metadata": {},
   "source": [
    "From the above, it looks like we can justify using about 200 inactive batches. It is common to use a moving window average in order to make this determination more quantitatively.\n",
    "\n",
    "Note that you will not want to run with Shannon entropy enabled all the time, because the simulation will be quite a bit slower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4716f",
   "metadata": {},
   "source": [
    "## Active batches\n",
    "\n",
    "The number of active batches (`settings.batches - settings.inactive`) are the number of tally realizations we use to accumulate tally statistics. The higher this number, the lower the statistical noise in our result (but remember that unless we properly chose the inactive batches, we could be PRECISE but WRONG!).\n",
    "\n",
    "The standard deviation in a Monte Carlo tally obeys the central limit theorem, assuming that each batch of neutrons is independent and identically distributed from other batches (more on this later). Then, \n",
    "\n",
    "$$ \\sigma\\propto\\frac{1}{\\sqrt{N}}$$\n",
    "\n",
    "where $N$ is the number of tally realizations. In other words, if we want to decrease the standard deviation in our simulation by a factor of 2, we would need to run 4 times as many particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20934086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-init the settings in order to remove the Shannon entropy mesh\n",
    "model.settings = openmc.Settings()\n",
    "\n",
    "space = openmc.stats.CartesianIndependent(x=x, y=y, z=z)\n",
    "model.settings.source = openmc.IndependentSource(space=space)\n",
    "\n",
    "model.settings.inactive = 100\n",
    "model.settings.batches = 200\n",
    "model.settings.particles = 500\n",
    "statepoint = model.run(apply_tally_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095da25",
   "metadata": {},
   "source": [
    "### Tally triggers\n",
    "\n",
    "You most likely will not know, the first time you run your model, what the statistical error will be in your tallies of interest (this will depend on how many \"scores\" occur to each tally). However, OpenMC has the ability to  keep running batches until a certain condition on a tally is met. These conditions can be set using the variance, standard deviation, or relative error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e1e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c4536c",
   "metadata": {},
   "source": [
    "Let's now have OpenMC keep adding batches until reaching a maximum relative error of 10% in the heating tally. With triggers, we need to tell OpenMC how frequently to check whether the triggers are satisfied (`batch_interval`) and a maximum number of batches to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00de26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558670a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "statepoint = model.run(apply_tally_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27b9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a58ba729",
   "metadata": {},
   "source": [
    "We can also add a trigger to the multiplication factor. When you have multiple triggers, the simulation will only terminate once all are satisfied (or you reach `max_batches`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1b6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24314d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "statepoint = model.run(apply_tally_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c0108",
   "metadata": {},
   "source": [
    "## Inter-Cycle Correlation\n",
    "\n",
    "For the central limit theorm to apply, each batch of particles which is used to assembly a tally realization should be INDEPENDENT. However, this is obviously not the case, since we sample the birth sites for neutrons in batch $i$ from the the fission sites from batch $i-1$. This is called \"inter-cycle correlation,\" and means that the actual variances reported by a Monte Carlo code *underpredict* the true variance.\n",
    "\n",
    "One way that you can increase the independence of batches is to set `settings.generations_per_batch` to a number greater than 1. This will effectively increase the independence of each batch by reduce the cross-correlation between the fission bank of other batches.\n",
    "\n",
    "You can quantify the extent of inter-cycle correlation by running OpenMC repeated times using different seeds. The mean and standard deviation of those estimates have the inter-cycle correlation removed. In order for these runs to be faster, we can drastically reduce the number of inactive batches (of course, our answers are wrong, but right now we are only exploring the inter-cycle correlation aspect, which is independent of the inactive batch choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8506c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tallies = []\n",
    "\n",
    "model.settings.trigger_active = False\n",
    "model.settings.inactive = 10\n",
    "model.settings.batches = 110\n",
    "model.settings.particles = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ab287",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "k_values = []\n",
    "k_std_dev_values = []\n",
    "while n <= 5:\n",
    "    # run OpenMC with different seeds\n",
    "        \n",
    "    print('Ran OpenMC with seed = {0} ... k = {1} +/- {2}'.format(n, k_values[-1], k_std_dev_values[-1]))\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.mean(k_values)\n",
    "std_dev = np.std(k_values)\n",
    "\n",
    "print(mean, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d1947",
   "metadata": {},
   "source": [
    "Notice how the standard deviation we compute of the multiple independent runs is HIGHER than the values reported from any individual OpenMC solve. This occurs because each batch is not truly independent of the other batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee32e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495760b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "k_values = []\n",
    "k_std_dev_values = []\n",
    "while n <= 5:\n",
    "    model.settings.seed = n\n",
    "    statepoint = model.run(output=False)\n",
    "    \n",
    "    with openmc.StatePoint(statepoint) as sp:\n",
    "        k_values.append(sp.keff.nominal_value)\n",
    "        k_std_dev_values.append(sp.keff.std_dev)\n",
    "        \n",
    "    print('Running OpenMC with seed = {0} ... k = {1} +/- {2}'.format(n, k_values[-1], k_std_dev_values[-1]))\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(k_values)\n",
    "std_dev = np.std(k_values)\n",
    "\n",
    "print(mean, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b0da7",
   "metadata": {},
   "source": [
    "Note how our sample standard deviation taken from multiple independent OpenMC runs is now closer to the value estimated from a single OpenMC run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
